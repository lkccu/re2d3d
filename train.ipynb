{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\pycharm-pro\\\\PyCharm 2022.2.3\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'E:\\\\pycharm-pro\\\\PyCharm 2022.2.3\\\\plugins\\\\python\\\\helpers\\\\pydev', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'F:\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\Demic-0.1', 'F:\\\\Python\\\\Python310\\\\python310.zip', 'F:\\\\Python\\\\Python310\\\\DLLs', 'F:\\\\Python\\\\Python310\\\\lib', 'F:\\\\Python\\\\Python310', '', 'C:\\\\Users\\\\HASEE\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'F:\\\\Python\\\\Python310\\\\lib\\\\site-packages', 'F:\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\win32', 'F:\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\win32\\\\lib', 'F:\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\Pythonwin', './raft/core', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\log', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\models', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch', '/raft-pytorch', 'core', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\log', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\models', '/raft-pytorch', 'core', './raft/core', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\log', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\models', '/raft-pytorch', 'core', './raft/core', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\raft1', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\log', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\models', '/raft-pytorch', 'core', './raft/core', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\log', 'E:\\\\course\\\\31\\\\machineLearning\\\\AIforMedicine\\\\re2D3D\\\\Pointnet_Pointnet2_pytorch\\\\models', '/raft-pytorch', 'core']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RAFT' from 'raft1' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mDIRN\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate_contour,PPCSolver,loss_dirn\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mraft1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mraft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RAFT \u001B[38;5;28;01mas\u001B[39;00m raft\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPointnet_Pointnet2_pytorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpointnet2_cls_msg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_model\n",
      "File \u001B[1;32mE:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\DIRN.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mraft1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sequence_loss\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#-------------------------------------------------------------------------------------------------------------------\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#------------------------3d canny detection-------------------------------------\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_contour\u001B[39m(V,dod,width,length):\n",
      "File \u001B[1;32mE:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\raft1\\train.py:18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mraft1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RAFT\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mevaluate\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'RAFT' from 'raft1' (unknown location)"
     ]
    }
   ],
   "source": [
    "#TODO import\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('./raft1/core')\n",
    "sys.path.append(r'E:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D')\n",
    "sys.path.append(r'E:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from DIRN import generate_contour,PPCSolver,loss_dirn\n",
    "from raft1.core.raft import RAFT as raft\n",
    "from Pointnet_Pointnet2_pytorch.models.pointnet2_cls_msg import get_model\n",
    "from argparse import Namespace\n",
    "from Barlow_Twins import wrapper\n",
    "from fenc import BasicEncoder\n",
    "from Barlow_Twins.loss import BarlowTwinsLoss as Loss_BT\n",
    "from torch.utils.data import Dataset\n",
    "import functools\n",
    "from CUT.models.patchnce import PatchNCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple/\n",
      "Requirement already satisfied: pynrrd in f:\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in f:\\python\\python310\\lib\\site-packages (from pynrrd) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in f:\\python\\python310\\lib\\site-packages (from pynrrd) (1.22.1)\n",
      "Requirement already satisfied: nptyping in f:\\python\\python310\\lib\\site-packages (from pynrrd) (2.4.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pynrrd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils import data\n",
    "from skimage import io\n",
    "from cv2.cv2 import resize\n",
    "import numpy as np\n",
    "#TODO utils & params including dataloaders,gpus,etc...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img_pth = r'E:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\drr_real\\2dImage'\n",
    "#2DIMAGE:_1:I_r  _2:I_fr   _3:I_m   _4:I_m_sa\n",
    "Vol_pth = r'E:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\drr_real\\volume'\n",
    "label_pth = 'path/to/label'\n",
    "#3D-CT:切记序号要与2Dimage一一对应\n",
    "\n",
    "#TODO 这里的标注可能还需要进行进一步的调整 因为一张VOl是对应多张2DImage的\n",
    "class MyDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for converting the data into batches.\n",
    "    The data.Dataset class is a pyTorch class which help\n",
    "    in speeding up  this process with effective parallelization\n",
    "    \"\"\"\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self,list_IDs):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        # Load data and get label\n",
    "        V =  torch.Tensor(\n",
    "            io.imread(Vol_pth)\n",
    "        )\n",
    "        #TODO 这里需不需要再进行一步处理过程呢 preprocess可不可以直接放在这儿做\n",
    "        I_r = torch.Tensor(\n",
    "            resize(io.imread(img_pth + ID + '_1.jpg'), (480, 480, 3)))\n",
    "        I_fr = torch.Tensor(\n",
    "            resize(io.imread(img_pth + ID + '_2.jpg'), (480, 480, 3)))\n",
    "        I_m = torch.Tensor(\n",
    "            resize(io.imread(img_pth + ID + '_3.jpg'), (480, 480, 3)))\n",
    "        I_m_sa = torch.Tensor(\n",
    "            resize(io.imread(img_pth + ID + '_4.jpg'), (480, 480, 3)))\n",
    "        with open(label_pth+ ID + '_.pickle', 'rb') as f:\n",
    "            T_gt = pickle.load(f)\n",
    "        T_gt = torch.Tensor(T_gt)\n",
    "\n",
    "        return I_r,I_fr,I_m,I_m_sa,V,T_gt\n",
    "\n",
    "# filename = list(set([x.split('_')[0]\n",
    "#                          for x in os.listdir(img_pth)]))\n",
    "# partition ={}\n",
    "# partition['train'], partition['validation'] = train_test_split(filename, test_size=0.33, random_state=42)\n",
    "#\n",
    "# params = {'batch_size': 16,\n",
    "#           'shuffle': True,\n",
    "#           'num_workers': 6,\n",
    "#           'worker_init_fn': np.random.seed(42)\n",
    "#         }\n",
    "#\n",
    "# train_dataset = MyDataset(partition['train'])\n",
    "# training_generator = data.DataLoader(train_dataset, **params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#TODO create my dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Namespace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [15], line 19\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03minput:args Namespace\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03moutput:nn.module,a modified model from raft\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[43mNamespace\u001B[49m(dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, alternate_corr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     20\u001B[0m small\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,mixed_precision\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_raft\u001B[39m():\n\u001B[0;32m     23\u001B[0m     model \u001B[38;5;241m=\u001B[39m raft(args)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Namespace' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO set config models\n",
    "\"\"\"\n",
    "input: none\n",
    "output: nn.module,a modified model from pointnet2\n",
    "\"\"\"\n",
    "\n",
    "def get_model_pointnet2():\n",
    "    classifier = nn.Sigmoid()\n",
    "    model = get_model(1)\n",
    "    model.fc3 = classifier\n",
    "\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input:args Namespace\n",
    "output:nn.module,a modified model from raft\n",
    "\"\"\"\n",
    "\n",
    "args = Namespace(dropout=True, alternate_corr=False,\n",
    "small=False,mixed_precision=False)\n",
    "\n",
    "def get_model_raft():\n",
    "    model = raft(args)\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input:?\n",
    "output:nn.module,A modified model from BT\n",
    "\"\"\"\n",
    "params = {\n",
    "\n",
    "}\n",
    "def get_model_BT():\n",
    "    model = wrapper.wrapper()\n",
    "    return model\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=1, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "        self.conv = nn.Conv2d(  in_channels=256,\n",
    "                        out_channels=64,\n",
    "                        kernel_size=1,\n",
    "                        stride=1)\n",
    "\n",
    "    def forward(self, input:torch.Tensor):\n",
    "        #TODO： We use 1×1 convolution to match the encoded feature map to the input channel dimension of the patch GAN discriminator.\n",
    "        #input channel: 256*32*32 ---> patch GAN input channel dimension?\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        input =self.conv(input)\n",
    "        return self.model(input)\n",
    "\n",
    "        #TODO:pnce loss func:\n",
    "#TODO 在训练的for循环中要把这个补上 BCE LOSS\n",
    "def get_model_AFE():#TODO done\n",
    "    input_nc = 64 # input_nc:num_channels TODO:把这个改成对的\n",
    "    AFE = NLayerDiscriminator(input_nc)\n",
    "    return AFE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#TODO train CUT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#TODO use CUT to implement domain adaptation\n",
    "\"\"\"\n",
    "input: Real X-ray image\n",
    "output: bone-projection style image\n",
    "\"\"\"\n",
    "def convert_to_drr(I_fr):\n",
    "    I_f = 0 # TODO 修改这个函数\n",
    "    return I_f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'update'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mDIRN\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03mTODO 构建一个我自己的model\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m输入的形式是以一张真实图像一张drr图像，\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03m其中real图像转化为DRR图像的部分我放在一个stand_alone_module\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03mforward而出的是一个Tpred\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#TODO how to implement data sharing\u001B[39;00m\n",
      "File \u001B[1;32mE:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\DIRN.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mraft1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sequence_loss\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#-------------------------------------------------------------------------------------------------------------------\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#------------------------3d canny detection-------------------------------------\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_contour\u001B[39m(V,dod,width,length):\n",
      "File \u001B[1;32mE:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\raft1\\train.py:18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mraft1\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mraft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RAFT\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mevaluate\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\n",
      "File \u001B[1;32mE:\\course\\31\\machineLearning\\AIforMedicine\\re2D3D\\raft1\\core\\raft.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mupdate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BasicUpdateBlock, SmallUpdateBlock\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mextractor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BasicEncoder, SmallEncoder\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcorr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CorrBlock, AlternateCorrBlock\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'update'"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "import random\n",
    "import numpy as np\n",
    "import DIRN\n",
    "\"\"\"\n",
    "TODO 构建一个我自己的model\n",
    "输入的形式是以一张真实图像一张drr图像，\n",
    "其中real图像转化为DRR图像的部分我放在一个stand_alone_module\n",
    "forward而出的是一个Tpred\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#TODO how to implement data sharing\n",
    "def flowmap_to_p1(flowmap,p):#都不是 是一个map的形式\n",
    "     a,b,c = p.shape\n",
    "     p1 = np.zeros((a,b,c))\n",
    "     p = np.nonzero(p)\n",
    "     for (x,y,z) in p:\n",
    "        p1[x+flowmap[x,y,z][0],y+flowmap[x,y,z][1],z+flowmap[x,y,z][2]] = 1 # TODO 可以稍微优化一下\n",
    "     return p1\n",
    "\n",
    "def concatate(n,p1,w,g):\n",
    "    #TODO:CONCANATE THEM INTO A MATRIX(how） compute xyz\n",
    "    xyz = np.concatenate(n,p1,w,g)# TODO 待补充\n",
    "    return xyz\n",
    "\n",
    "class MyDIRN(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.pointnet = get_model_pointnet2()\n",
    "        self.raft = get_model_raft()\n",
    "        self.fenc = BasicEncoder()\n",
    "    def forward(self,I_m:torch.Tensor,I_fr:torch.Tensor,V):#So我们在做generater的时候一定要做三个都有的dataloader\n",
    "        w,g,p = generate_contour(V)\n",
    "        I_f = convert_to_drr(I_fr)\n",
    "\n",
    "        flowmap = self.raft(I_f,I_m)#这段跑起来的时候可能得要修改一下\n",
    "        p1 =flowmap_to_p1(flowmap,w,g)\n",
    "        N_fl = len(flowmap)\n",
    "        N_cp = len(np.nonzero(p))\n",
    "        n = np.dot(w,g,p1)\n",
    "        xyz = concatate(n,p1,w,g)#concanate还没有改\n",
    "\n",
    "        W = self.pointnet(xyz)\n",
    "        dv = PPCSolver(p1,w,g,W)\n",
    "\n",
    "        Tpred = dv\n",
    "\n",
    "        return Tpred,W,dv,flowmap,N_fl,N_cp\n",
    "\n",
    "    def loss(self,N_fl,N_cp,Tpred,T_gt,dv,W,f,f_gt,M_p):\n",
    "        return DIRN.loss_dirn(N_fl,N_cp,Tpred,T_gt,dv,W,f,f_gt,M_p)\n",
    "\n",
    "class MyBT(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.barlowTwins = get_model_BT()\n",
    "        self.fenc = BasicEncoder()\n",
    "        self.loss = Loss_BT()\n",
    "    def forward(self,Im:torch.Tensor,Imsa:torch.Tensor):\n",
    "\n",
    "        fmap_Im = self.fenc(Im)\n",
    "        fmap_Imsa = self.fenc(Imsa)\n",
    "        Z_m = self.barlowTwins(fmap_Im)\n",
    "        Z_msa = self.barlowTwins(fmap_Imsa)\n",
    "\n",
    "        return Z_m,Z_msa\n",
    "\n",
    "    def BTloss(self,Z_m:torch.Tensor,Z_msa:torch.Tensor):\n",
    "        btloss = self.loss(Z_m,Z_msa)\n",
    "        return btloss\n",
    "\n",
    "class MyAFE(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.fenc = BasicEncoder()\n",
    "        self.AFE = get_model_AFE()\n",
    "\n",
    "    def forward(self,I_fr:torch.Tensor,I_r:torch.Tensor):\n",
    "        I_f = convert_to_drr(I_fr)\n",
    "        fmap_I_f = self.fenc(I_f)\n",
    "        fmap_I_r = self.fenc(I_r)\n",
    "        random_index = random.randrange(0,1)\n",
    "        if random_index ==0:\n",
    "            ran_fmap = fmap_I_f\n",
    "        else:\n",
    "            ran_fmap = fmap_I_r\n",
    "        Ypred = self.AFE(ran_fmap)\n",
    "        return Ypred\n",
    "\n",
    "    def loss(self,Y_pred,label):\n",
    "        return nn.BCELoss(Y_pred,label)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.afe = MyAFE()\n",
    "        self.bt = MyBT()\n",
    "        self.DIRN = MyDIRN()\n",
    "\n",
    "    def forward(self,I_r:torch.Tensor,I_fr:torch.Tensor,I_m:torch.Tensor,I_m_sa:torch.Tensor,V:torch.Tensor):\n",
    "\n",
    "        Z_m,Z_msa = self.bt(I_m,I_m_sa)\n",
    "        Tpred,W,dv,flowmap,N_fl,N_cp = self.DIRN(I_m,I_fr,V)\n",
    "        Ypred = self.afe(I_fr,I_r)\n",
    "\n",
    "        return Z_m,Z_msa,Tpred,Ypred,W,dv,flowmap,N_fl,N_cp\n",
    "\n",
    "    def losstotal(self,\n",
    "                  Z_m,\n",
    "                  Z_msa,\n",
    "                  Tpred,\n",
    "                  W,\n",
    "                  dv,\n",
    "                  Ypred,\n",
    "                  flowmap,\n",
    "                  N_fl,\n",
    "                  N_cp,\n",
    "                  T_gt,\n",
    "                  f_gt,\n",
    "                  M_p,\n",
    "                  label):\n",
    "        return torch.Tensor(0.05*self.bt(Z_m,Z_msa)+0.2*self.afe(Ypred,label)+self.DIRN.loss(N_fl,N_cp,Tpred,T_gt,dv,W,flowmap,f_gt,M_p))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#TODO train model & save models\n",
    "#TODO 修改forward，建立网络前后的连接模型  training:是用images进行训练的 eval：\n",
    "\"\"\"\n",
    "raft:\n",
    "      input:2*images 640*480(Centercrop) ----> 480 * 480(resized) ------>  imagesize:[256 ,256]\n",
    "      output:Ir: 1 * fmap [256, 32, 32]  If: 1 * cmap[256,32,32]\n",
    "      output:Tpred converted from dv size: unknown\n",
    "pointnet2:\n",
    "    input: p1,n,w,g\n",
    "    output:W a diagonal matrix Ncp * Ncp\n",
    "3d_canny_edge_detection:\n",
    "    input: V nii.gz\n",
    "    output: w ,g size:unknown(can be tracked)\n",
    "deepdrr:\n",
    "    input : V nii\n",
    "    output : Idrr (640*480) can be loaded before training\n",
    "CUT:\n",
    "    input:Ir & Iadv size:256*256\n",
    "    output : none loss_fn(what)\n",
    "Barlow Twins:\n",
    "    input :1 cmap [256,32,32] 1 fmap [256,32,32]\n",
    "    output:\n",
    "PPCsolver:\n",
    "    input:W,P,P1\n",
    "    output:Tpred\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"ATTENTION:所有在这里面的数据的格式都是tensor()\"\"\"\n",
    "\n",
    "#TODO：CUDA是怎么实装到上面去的\n",
    "if torch.cuda.is_available():\n",
    "   MyModel = MyModel.cuda()\n",
    "optimizer = torch.optim.Adam(MyModel.parameters(),lr=1e-4)#TODO 名称待补充\n",
    "\n",
    "epoch = 0\n",
    "for data in train_loader :\n",
    "    ID,V,I_r,I_fr,I_m,I_m_sa,T_gt = data\n",
    "    if torch.cuda.is_available():\n",
    "        V = V.cuda()\n",
    "        I_r = I_r.cuda()\n",
    "        I_fr = I_fr.cuda()\n",
    "        I_m = I_m.cuda()\n",
    "        I_m_sa = I_m_sa.cuda()\n",
    "    Z_m,Z_msa,Tpred,Ypred,W,dv,flowmap,N_fl,N_cp = MyModel(I_r,I_fr,I_m,I_m_sa,V)\n",
    "    loss = MyModel.losstotal(Z_m,\n",
    "                  Z_msa,\n",
    "                  Tpred,\n",
    "                  W,\n",
    "                  dv,\n",
    "                  Ypred,\n",
    "                  flowmap,\n",
    "                  N_fl,\n",
    "                  N_cp,\n",
    "                  T_gt,\n",
    "                  f_gt,\n",
    "                  M_p,\n",
    "                  label)\n",
    "    print_loss = loss.data.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch+=1\n",
    "\n",
    "    if epoch%50 == 0:\n",
    "        print('epoch: {},loss: {:,4}'.format(epoch,print_loss))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "file= r'0.nii.gz'\n",
    "file[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((128,256,512))\n",
    "a.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "12.0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(128/10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
